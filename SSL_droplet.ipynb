{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL_seg import unsupervised_segmentation\n",
    "from dataset_utils import SSL_config\n",
    "dataset_config = SSL_config.get_config('data_droplet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to create the reduced size images and masks using clustering and morphological closing.\n",
    "# If visualization is set to TRUE, this will automaticall visualize the results\n",
    "## You need to specify the dimater of the tubes for every folder\n",
    "Area_list,Diameter_list,masks,images,brightSpot_indices,org_imgs,y2 = unsupervised_segmentation('data_droplet').crop(left_crop=0,visualization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN this when you want to save the cropped droplet images and masks for first supervised segmentation training.\n",
    "# This will create the reduced size data.\n",
    "unsupervised_segmentation('data_droplet').save_crop(real_img_list=images,segmented_img_list=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the following line to convert reduced size images and masks for full size (original size)\n",
    "full_seg_list,full_img_list = unsupervised_segmentation('data_droplet').coordinate_mapping(org_imgs,masks,y2,brightSpot_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import DropNet\n",
    "# Specify the dataset type, the first training is on reduced data and the second training is on full data\n",
    "IoU_perEpoch_train,IoU_perEpoch_val,loss_perEpoch_train, loss_perEpoch_val = DropNet(config='train_droplet',data='reduced_data').training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot and save training process results\n",
    "DropNet(config='train_droplet',data='reduced_data').plot_results(loss_perEpoch_train,loss_perEpoch_val,IoU_perEpoch_val,IoU_perEpoch_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following lines for evaluating the model performance on test dataset (target masks available)\n",
    "# Specify the data type by choosing either 'reduced_data' or 'full_data'\n",
    "import inference\n",
    "test_iou,test_pred_mask,test_dataset = inference.generate_predictions(data_type='reduced_data',split='Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the following lines for visualization of the segmentation results\n",
    "# Specify whether ground truth masks are available or not\n",
    "# Specify if there is a new image directory. If not, it will take data from the original dataset directory.\n",
    "inference.visualize_predictions(data_type='full_data',split='Val',img_h=1920,img_w=1080,gt_mask=True,IMG_DIR=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following line to obtain droplets sizes\n",
    "IMG_DIR = 'Specify/the/directory/to/images'\n",
    "Area_list,Diameter_list = inference.droplet_size(IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the following line to obtain droplet velocity\n",
    "IMG_DIR = 'Specify/the/directory/to/images'\n",
    "v_0 = inference.velocity_droplet(IMG_DIR=IMG_DIR,height_crop=950,fps=600,resolution=1920)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
